{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60ca830-ea03-4e4b-a062-1a0f39721cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyTDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44170c76-4427-4355-8aee-d5469d7e110e",
   "metadata": {},
   "source": [
    "### Imports & Hyperprameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d69e32-88e7-4087-a6f4-7211c2b5a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
    "from transformers import BertModel,BertTokenizer\n",
    "import time\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import string\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9af923d-b002-46b4-b1f3-0845e460931f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06bd9dca-a8b2-46fe-8125-6d0400831ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "freeze_prot_encoder = False\n",
    "freeze_disease_encoder = False\n",
    "batch_size = 6\n",
    "\n",
    "prot_encoder_path = \"Rostlab/prot_bert\"\n",
    "text_encoder_path = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "\n",
    "prot_tokenizer = BertTokenizer.from_pretrained(prot_encoder_path, do_lower_case=False )\n",
    "prot_model = BertModel.from_pretrained(prot_encoder_path)\n",
    "prot_model = prot_model.to(device)\n",
    "\n",
    "text_tokenizer = BertTokenizer.from_pretrained(text_encoder_path)\n",
    "text_model = BertModel.from_pretrained(text_encoder_path)\n",
    "text_model = text_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbc1e67-93e9-4c29-8dbf-82fa9e8472cb",
   "metadata": {},
   "source": [
    "### Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7adecdce-ef82-4928-af86-57820a342392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GDANet(torch.nn.Module):\n",
    "    def __init__(self, prot_encoder, disease_encoder, prot_out_dim=1024, disease_out_dim=768, drop_out=0, freeze_prot_encoder=True,  freeze_disease_encoder=True):\n",
    "        super(GDANet, self).__init__()\n",
    "        self.prot_encoder = prot_encoder\n",
    "        self.disease_encoder = disease_encoder\n",
    "        self.freeze_encoders(freeze_prot_encoder,freeze_disease_encoder)\n",
    "        \n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(prot_out_dim + disease_out_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(drop_out),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    \n",
    "    def freeze_encoders(self,freeze_prot_encoder,freeze_disease_encoder):\n",
    "        if freeze_prot_encoder:\n",
    "            print(f\"freeze_prot_encoder:{freeze_prot_encoder}\")\n",
    "            for param in self.prot_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            for param in self.disease_encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "        if freeze_disease_encoder:\n",
    "            print(f\"freeze_disease_encoder:{freeze_disease_encoder}\")\n",
    "            for param in self.disease_encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            for param in self.disease_encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "                \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.prot_encoder(x1)[0][:,0]\n",
    "        x2 = self.disease_encoder(x2)[0][:,0]\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        x = self.reg(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab22becf-82dd-4417-b18e-abe37962a98a",
   "metadata": {},
   "source": [
    "### Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161504dc-f8b8-48c0-a58d-0c10290297d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisGeNETProcessor():\n",
    "    def __init__(self, data_dir=\"./data\"):\n",
    "        from tdc.multi_pred import GDA\n",
    "        data = GDA(name = 'DisGeNET',path=data_dir)\n",
    "        self.datasets = data.get_split()\n",
    "\n",
    "    def get_train_examples(self):\n",
    "        return self.datasets[\"train\"][\"Gene\"].values,self.datasets[\"train\"][\"Disease\"].values,self.datasets[\"train\"][\"Y\"].values\n",
    "\n",
    "    def get_dev_examples(self):\n",
    "        return self.datasets[\"valid\"][\"Gene\"].values,self.datasets[\"valid\"][\"Disease\"].values,self.datasets[\"valid\"][\"Y\"].values\n",
    "\n",
    "    def get_test_examples(self):\n",
    "        return self.datasets[\"test\"][\"Gene\"].values,self.datasets[\"test\"][\"Disease\"].values,self.datasets[\"test\"][\"Y\"].values\n",
    "    \n",
    "def convert_examples_to_tokens(examples, prot_tokenizer, text_tokenizer, max_seq_length=512, test=False):\n",
    "\n",
    "    first_sentences = []\n",
    "    second_sentences = []\n",
    "    labels = []\n",
    "    for gene, disease,label in zip(*examples):\n",
    "        first_sentences.append([\" \".join(gene)])\n",
    "        second_sentences.append([disease])\n",
    "        labels.append([label])\n",
    "\n",
    "    # Flatten out\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "    if test:\n",
    "        first_sentences = first_sentences[:1024]\n",
    "        second_sentences = second_sentences[:1024]\n",
    "        labels = labels[:1024]\n",
    "    \n",
    "    print(\"start tokenizing ...\")\n",
    "    # Tokenize\n",
    "    prot_tokens = prot_tokenizer(\n",
    "        first_sentences,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "    )[\"input_ids\"]\n",
    "    # Tokenize\n",
    "    text_tokens = text_tokenizer(\n",
    "        second_sentences,\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length,\n",
    "        padding=\"max_length\",\n",
    "    )[\"input_ids\"]\n",
    "    \n",
    "    print(\"finish tokenizing ...\")\n",
    "    \n",
    "    inputs = {\n",
    "    }\n",
    "    inputs[\"prot_tokens\"] = prot_tokens\n",
    "    inputs[\"text_tokens\"] = text_tokens\n",
    "    inputs[\"labels\"] = labels\n",
    "    return inputs\n",
    "\n",
    "def convert_tokens_to_tensors(tokens, device='cpu'):\n",
    "    input_dict = {}\n",
    "    prot_inputs = torch.tensor(tokens[\"prot_tokens\"], dtype=torch.long, device=device)\n",
    "    text_inputs = torch.tensor(tokens[\"text_tokens\"], dtype=torch.long, device=device)\n",
    "    labels_inputs = torch.tensor(tokens[\"labels\"], dtype=torch.float, device=device)\n",
    "    input_dict[\"prot_input\"] = prot_inputs\n",
    "    input_dict[\"text_inputs\"] = text_inputs\n",
    "    input_dict[\"label_inputs\"] = labels_inputs\n",
    "    return input_dict\n",
    "\n",
    "# Test\n",
    "# disGeNET = DisGeNETProcessor()\n",
    "# examples = disGeNET.get_train_examples() \n",
    "# tokens = convert_examples_to_tokens(examples, prot_tokenizer, text_tokenizer, max_seq_length=5,test=True)\n",
    "# inputs = convert_tokens_to_tensors(tokens, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad0af9-b326-4476-b9f4-f5d22c73139e",
   "metadata": {},
   "source": [
    "### Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc258b9d-e816-49e7-a3c3-ed76a0fc41e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokenizing ...\n",
      "finish tokenizing ...\n",
      "start tokenizing ...\n",
      "finish tokenizing ...\n",
      "start tokenizing ...\n",
      "finish tokenizing ...\n"
     ]
    }
   ],
   "source": [
    "def train_an_epoch(model,train_dataloader,optimizer, loss):\n",
    "    model.train()\n",
    "    t_loss = 0 \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        prot_input, text_inputs, label_inputs = batch\n",
    "        optimizer.zero_grad()\n",
    "        out = model(prot_input, text_inputs)\n",
    "        output = loss(out, label_inputs)\n",
    "        t_loss += output.item()\n",
    "        output.backward()\n",
    "        optimizer.step()\n",
    "    return t_loss\n",
    "\n",
    "def evaluate(model,test_dataloader, metric):\n",
    "    model.eval()\n",
    "    metric_val = 0 \n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(test_dataloader):\n",
    "            prot_input, text_inputs, label_inputs = batch\n",
    "            optimizer.zero_grad()\n",
    "            out = model(prot_input, text_inputs)\n",
    "            output = metric(out, label_inputs)\n",
    "            metric_val += output.item()\n",
    "    return metric_val/(step+1)\n",
    "\n",
    "disGeNET = DisGeNETProcessor()\n",
    "# Train data_loader\n",
    "examples = disGeNET.get_train_examples() \n",
    "# tokens = convert_examples_to_tokens(examples, prot_tokenizer, text_tokenizer, test=True)  ## Trun the test off if doing the real training\n",
    "tokens = convert_examples_to_tokens(examples, prot_tokenizer, text_tokenizer)\n",
    "\n",
    "inputs = convert_tokens_to_tensors(tokens, device)\n",
    "train_data = TensorDataset(\n",
    "    inputs[\"prot_input\"], inputs[\"text_inputs\"], inputs[\"label_inputs\"]\n",
    ")\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# Validation data_loader\n",
    "valid_examples = disGeNET.get_dev_examples() \n",
    "# valid_tokens = convert_examples_to_tokens(valid_examples, prot_tokenizer, text_tokenizer, test=True)  ## Trun the test off if doing the real training\n",
    "valid_tokens = convert_examples_to_tokens(valid_examples, prot_tokenizer, text_tokenizer)\n",
    "\n",
    "valid_inputs = convert_tokens_to_tensors(valid_tokens, device)\n",
    "valid_data = TensorDataset(\n",
    "    valid_inputs[\"prot_input\"], valid_inputs[\"text_inputs\"], valid_inputs[\"label_inputs\"]\n",
    ")\n",
    "valid_sampler = RandomSampler(valid_data)\n",
    "\n",
    "# Test data_loader\n",
    "test_examples = disGeNET.get_test_examples() \n",
    "# test_tokens = convert_examples_to_tokens(test_examples, prot_tokenizer, text_tokenizer, test=True)  ## Trun the test off if doing the real training\n",
    "test_tokens = convert_examples_to_tokens(test_examples, prot_tokenizer, text_tokenizer)\n",
    "\n",
    "test_inputs = convert_tokens_to_tensors(test_tokens, device)\n",
    "test_data = TensorDataset(\n",
    "    test_inputs[\"prot_input\"], test_inputs[\"text_inputs\"], test_inputs[\"label_inputs\"]\n",
    ")\n",
    "test_sampler = RandomSampler(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b17af4-7dea-4b0c-b5a9-0060c901353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmengzaiqiao\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.15"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/protbert/notebooks/wandb/run-20220424_183006-32ca6exh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mengzaiqiao/protbert/runs/32ca6exh\" target=\"_blank\">lyric-planet-25</a></strong> to <a href=\"https://wandb.ai/mengzaiqiao/protbert\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze_prot_encoder:True\n",
      "freeze_disease_encoder:True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0333c91bd40c4a9bc38e470c25436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for lr in [1e-4]:\n",
    "    # lr = 1e-4\n",
    "    patience = 5\n",
    "    dropout = 0.0\n",
    "    timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    random_str = \"\".join([random.choice(string.ascii_lowercase) for n in range(6)])\n",
    "    best_model_dir = f\"../model/model_{timestamp_str}_{random_str}/\"\n",
    "\n",
    "    if not os.path.exists(best_model_dir):\n",
    "        os.makedirs(best_model_dir, exist_ok = False) \n",
    "\n",
    "    wandb.init(project=\"protbert\")\n",
    "    args = {}\n",
    "    args[\"batch_size\"] = batch_size\n",
    "    args[\"lr\"] = lr\n",
    "    args[\"dropout\"] = dropout\n",
    "    args[\"best_model_dir\"] = best_model_dir\n",
    "    args[\"prot_encoder_path\"] = prot_encoder_path\n",
    "    args[\"batch_size\"] = batch_size\n",
    "    args[\"patience\"] = patience\n",
    "    args[\"best_model_dir\"] = best_model_dir\n",
    "    args[\"freeze_prot_encoder\"] = freeze_prot_encoder\n",
    "    args[\"freeze_disease_encoder\"] = freeze_disease_encoder\n",
    "    args[\"device\"] = device\n",
    "\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_data, sampler=train_sampler, batch_size=batch_size\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_data, sampler=valid_sampler, batch_size=batch_size\n",
    "    )\n",
    "    test_dataloader = DataLoader(\n",
    "        test_data, sampler=test_sampler, batch_size=batch_size\n",
    "    )\n",
    "    wandb.config.update(args)\n",
    "    model = GDANet(prot_model, text_model, freeze_prot_encoder=True, freeze_disease_encoder=True).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    loss = nn.MSELoss()\n",
    "    metric = nn.MSELoss(reduction='sum')\n",
    "    best_dev_mse = sys.maxsize\n",
    "    unimproved_iters = 0\n",
    "    for epoch in tqdm(range(200), desc=\"Training\"):\n",
    "        epoch_loss = train_an_epoch(model, train_dataloader, optimizer, loss)\n",
    "        print(\"epoch_loss:\\t\",epoch_loss)\n",
    "        valid_mse = evaluate(model,valid_dataloader,metric)\n",
    "        test_mse = evaluate(model,test_dataloader,metric)\n",
    "        print(\"valid_mse:\\t\",valid_mse)\n",
    "        print(\"test_mse:\\t\",test_mse)\n",
    "        wandb.log({'epoch':epoch,'epoch_loss': epoch_loss, 'valid_mse': valid_mse, 'test_mse': test_mse})\n",
    "        # Update validation results\n",
    "        if valid_mse < best_dev_mse:\n",
    "            unimproved_iters = 0\n",
    "            best_dev_mse = valid_mse\n",
    "            torch.save(model, best_model_dir + \"model.bin\")\n",
    "        else:\n",
    "            unimproved_iters += 1\n",
    "            if unimproved_iters >= patience:\n",
    "                early_stop = True\n",
    "                tqdm.write(f\"Early Stopped on Epoch: {epoch}, Best Dev MSE: {best_dev_mse}\")\n",
    "                break\n",
    "    wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
